{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "48qJjNgxaTtl"
   },
   "source": [
    "# Google BERT on fake_or_real news dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HczePp89a8qh"
   },
   "source": [
    "# 1. Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rm_j49Kpodd3"
   },
   "source": [
    "### 1.1 Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DhKk6qc0YdEB"
   },
   "outputs": [],
   "source": [
    "## parameters Setting\n",
    "par_cased = 0 # default cased, 0 means uncased\n",
    "par_cleanup = 1 # default cleanup, 0 means non-cleanup\n",
    "par_eda = 1 # default eda, 0 means non-eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f9j8ZTWWk3ZS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: pytorch_pretrained_bert in /usr/local/lib/python3.5/dist-packages (0.6.2)\n",
      "Requirement already satisfied: nlpaug in /usr/local/lib/python3.5/dist-packages (0.0.7)\n",
      "Requirement already satisfied: bert in /usr/local/lib/python3.5/dist-packages (2.2.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.5/dist-packages (3.0.3)\n",
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.5/dist-packages (0.0)\n",
      "Requirement already satisfied: librosa in /usr/local/lib/python3.5/dist-packages (0.7.0)\n",
      "Requirement already satisfied: SoundFile in /usr/local/lib/python3.5/dist-packages (0.10.2)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.5/dist-packages (3.4.5)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.5/dist-packages (0.24.2)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.5/dist-packages (from pytorch_pretrained_bert) (1.9.213)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.5/dist-packages (from pytorch_pretrained_bert) (1.16.3)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.5/dist-packages (from pytorch_pretrained_bert) (2019.8.19)\n",
      "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.5/dist-packages (from pytorch_pretrained_bert) (1.2.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.5/dist-packages (from pytorch_pretrained_bert) (4.34.0)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from pytorch_pretrained_bert) (2.9.1)\n",
      "Requirement already satisfied: erlastic in /usr/local/lib/python3.5/dist-packages (from bert) (2.0.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.5/dist-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.5/dist-packages (from matplotlib) (2.8.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.5/dist-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.5/dist-packages (from matplotlib) (2.4.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.5/dist-packages (from sklearn) (0.21.3)\n",
      "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.5/dist-packages (from librosa) (2.1.8)\n",
      "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.5/dist-packages (from librosa) (0.45.1)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.5/dist-packages (from librosa) (4.4.0)\n",
      "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.5/dist-packages (from librosa) (1.12.0)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.5/dist-packages (from librosa) (1.3.1)\n",
      "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.5/dist-packages (from librosa) (0.2.2)\n",
      "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.5/dist-packages (from librosa) (0.13.2)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.5/dist-packages (from SoundFile) (1.12.3)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.5/dist-packages (from pandas) (2019.2)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.5/dist-packages (from boto3->pytorch_pretrained_bert) (0.9.4)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.213 in /usr/local/lib/python3.5/dist-packages (from boto3->pytorch_pretrained_bert) (1.12.213)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.5/dist-packages (from boto3->pytorch_pretrained_bert) (0.2.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.5/dist-packages (from kiwisolver>=1.0.1->matplotlib) (41.0.1)\n",
      "Requirement already satisfied: llvmlite>=0.29.0dev0 in /usr/local/lib/python3.5/dist-packages (from numba>=0.38.0->librosa) (0.29.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.5/dist-packages (from cffi>=1.0->SoundFile) (2.19)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.5/dist-packages (from botocore<1.13.0,>=1.12.213->boto3->pytorch_pretrained_bert) (0.15.2)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20; python_version >= \"3.4\" in /usr/local/lib/python3.5/dist-packages (from botocore<1.13.0,>=1.12.213->boto3->pytorch_pretrained_bert) (1.25.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch_pretrained_bert nlpaug bert matplotlib sklearn librosa SoundFile nltk pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UVrPSzwEd1Eq"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from random import randrange\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import nlpaug.augmenter.char as nac\n",
    "#import nlpaug.augmenter.word as naw\n",
    "import nlpaug.flow as naf\n",
    "from nlpaug.util import Action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bCXvOPmwpkB_"
   },
   "source": [
    "### 1.2 Set tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "Xe4FwqLHkmXE",
    "outputId": "c9073314-6c4d-4993-83bc-ec902fed2fb9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.tokenization:loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "if par_cased ==1:\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "else:\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xd6BHpq7p5Sn"
   },
   "source": [
    "### 1.3 Define Bert config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eszq-eKKlGIs"
   },
   "outputs": [],
   "source": [
    "class BertLayerNorm(nn.Module):\n",
    "        def __init__(self, hidden_size, eps=1e-12):\n",
    "            \"\"\"Construct a layernorm module in the TF style (epsilon inside the square root).\n",
    "            \"\"\"\n",
    "            super(BertLayerNorm, self).__init__()\n",
    "            self.weight = nn.Parameter(torch.ones(hidden_size))\n",
    "            self.bias = nn.Parameter(torch.zeros(hidden_size))\n",
    "            self.variance_epsilon = eps\n",
    "\n",
    "        def forward(self, x):\n",
    "            u = x.mean(-1, keepdim=True)\n",
    "            s = (x - u).pow(2).mean(-1, keepdim=True)\n",
    "            x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n",
    "            return self.weight * x + self.bias\n",
    "        \n",
    "\n",
    "class BertForSequenceClassification(nn.Module):\n",
    "    \"\"\"BERT model for classification.\n",
    "    This module is composed of the BERT model with a linear layer on top of\n",
    "    the pooled output.\n",
    "    Params:\n",
    "        `config`: a BertConfig class instance with the configuration to build a new model.\n",
    "        `num_labels`: the number of classes for the classifier. Default = 2.\n",
    "    Inputs:\n",
    "        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
    "            with the word token indices in the vocabulary. Items in the batch should begin with the special \"CLS\" token. (see the tokens preprocessing logic in the scripts\n",
    "            `extract_features.py`, `run_classifier.py` and `run_squad.py`)\n",
    "        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\n",
    "            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to\n",
    "            a `sentence B` token (see BERT paper for more details).\n",
    "        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\n",
    "            selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\n",
    "            input sequence length in the current batch. It's the mask that we typically use for attention when\n",
    "            a batch has varying length sentences.\n",
    "        `labels`: labels for the classification output: torch.LongTensor of shape [batch_size]\n",
    "            with indices selected in [0, ..., num_labels].\n",
    "    Outputs:\n",
    "        if `labels` is not `None`:\n",
    "            Outputs the CrossEntropy classification loss of the output with the labels.\n",
    "        if `labels` is `None`:\n",
    "            Outputs the classification logits of shape [batch_size, num_labels].\n",
    "    Example usage:\n",
    "    ```python\n",
    "    # Already been converted into WordPiece token ids\n",
    "    input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])\n",
    "    input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])\n",
    "    token_type_ids = torch.LongTensor([[0, 0, 1], [0, 1, 0]])\n",
    "    config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,\n",
    "        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)\n",
    "    num_labels = 2\n",
    "    model = BertForSequenceClassification(config, num_labels)\n",
    "    logits = model(input_ids, token_type_ids, input_mask)\n",
    "    ```\n",
    "    \"\"\"\n",
    "    def __init__(self, num_labels=2):\n",
    "        super(BertForSequenceClassification, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        if par_cased ==1:\n",
    "            self.bert = BertModel.from_pretrained('/home/notebooks/cased')\n",
    "        else:\n",
    "            self.bert = BertModel.from_pretrained('/home/notebooks/uncased')\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, num_labels)\n",
    "        nn.init.xavier_normal_(self.classifier.weight)\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
    "        _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        return logits\n",
    "    def freeze_bert_encoder(self):\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def unfreeze_bert_encoder(self):\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "id": "kAHV3y9HlJpx",
    "outputId": "7bcc61c8-3cf1-4c73-b38a-2413c686bedd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "INFO:pytorch_pretrained_bert.modeling:extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpnj30gsw7\n",
      "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pytorch_pretrained_bert import BertConfig\n",
    "\n",
    "config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,\n",
    "        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)\n",
    "\n",
    "num_labels = 2\n",
    "model = BertForSequenceClassification(num_labels)\n",
    "\n",
    "# Convert inputs to PyTorch tensors\n",
    "#tokens_tensor = torch.tensor([tokenizer.convert_tokens_to_ids(zz)])\n",
    "\n",
    "#logits = model(tokens_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HEiltYWBeY9s"
   },
   "source": [
    "## 2. Dataset Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "P_7X9LLtlLRy",
    "outputId": "8d6d8fa3-d55c-4f5b-de5a-9ecf4fb73cde"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>title_vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary‚Äôs Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>[ 1.1533764e-02  4.2144405e-03  1.9692603e-02 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>[ 0.11267698  0.02518966 -0.00212591  0.021095...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>[ 0.04253004  0.04300297  0.01848392  0.048672...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>‚Äî Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>[ 0.10801624  0.11583211  0.02874823  0.061732...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>[ 1.69016439e-02  7.13498285e-03 -7.81233795e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary‚Äôs Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \\\n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE   \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE   \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL   \n",
       "3  ‚Äî Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE   \n",
       "4  It's primary day in New York and front-runners...  REAL   \n",
       "\n",
       "                                       title_vectors  \n",
       "0  [ 1.1533764e-02  4.2144405e-03  1.9692603e-02 ...  \n",
       "1  [ 0.11267698  0.02518966 -0.00212591  0.021095...  \n",
       "2  [ 0.04253004  0.04300297  0.01848392  0.048672...  \n",
       "3  [ 0.10801624  0.11583211  0.02874823  0.061732...  \n",
       "4  [ 1.69016439e-02  7.13498285e-03 -7.81233795e-...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dat = pd.read_csv('/home/notebooks/fake_or_real_news.csv')\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jj0-xALBl_pi"
   },
   "source": [
    "### 2.1 Convert label into binary text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "ti-rFJeml6qk",
    "outputId": "3caef643-8011-4c6f-dc55-36fc69cb3811"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You Can Smell Hillary‚Äôs Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>‚Äî Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                       You Can Smell Hillary‚Äôs Fear   \n",
       "1  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        Kerry to go to Paris in gesture of sympathy   \n",
       "3  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...     1  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...     1  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...     0  \n",
       "3  ‚Äî Kaydee King (@KaydeeKing) November 9, 2016 T...     1  \n",
       "4  It's primary day in New York and front-runners...     0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = dat.drop(columns=['Unnamed: 0', 'title_vectors'])\n",
    "for i in range(len(dat)):\n",
    "    if dat.loc[i, 'label'] == \"REAL\": #REAL equal 0\n",
    "        dat.loc[i, 'label'] = 0\n",
    "    elif dat.loc[i, 'label'] == \"FAKE\": #FAKE equal 1\n",
    "        dat.loc[i, 'label'] = 1\n",
    "    if dat.loc[i, 'text'] == \"\":\n",
    "        dat = dat.drop([i])\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YbO6gis_fUK-"
   },
   "source": [
    "### 2.2 Combine the title and text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GaROtLAonfB6"
   },
   "outputs": [],
   "source": [
    "dat_plus = dat.copy()\n",
    "dat_plus['title_text']=dat['title']+'. '+dat['text']\n",
    "dat_plus = dat_plus.drop(columns=['title', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "elYz7QWKtr40",
    "outputId": "3997b365-6c16-4bec-855f-4e3ff33c397e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       You Can Smell Hillary‚Äôs Fear. Daniel Greenfiel...\n",
       "1       Watch The Exact Moment Paul Ryan Committed Pol...\n",
       "2       Kerry to go to Paris in gesture of sympathy. U...\n",
       "3       Bernie supporters on Twitter erupt in anger ag...\n",
       "4       The Battle of New York: Why This Primary Matte...\n",
       "5       Tehran, USA.   \\nI‚Äôm not an immigrant, but my ...\n",
       "6       Girl Horrified At What She Watches Boyfriend D...\n",
       "7       ‚ÄòBritain‚Äôs Schindler‚Äô Dies at 106. A Czech sto...\n",
       "8       Fact check: Trump and Clinton at the 'commande...\n",
       "9       Iran reportedly makes new push for uranium con...\n",
       "10      With all three Clintons in Iowa, a glimpse at ...\n",
       "11      Donald Trump‚Äôs Shockingly Weak Delegate Game S...\n",
       "12      Strong Solar Storm, Tech Risks Today | S0 News...\n",
       "13      10 Ways America Is Preparing for World War 3. ...\n",
       "14      Trump takes on Cruz, but lightly. Killing Obam...\n",
       "15      How women lead differently. As more women move...\n",
       "16      Shocking! Michele Obama & Hillary Caught Glamo...\n",
       "17      Hillary Clinton in HUGE Trouble After America ...\n",
       "18      What's in that Iran bill that Obama doesn't li...\n",
       "19      The 1 chart that explains everything you need ...\n",
       "20      The slippery slope to Trump‚Äôs proposed ban on ...\n",
       "21      Episode #160 ‚Äì SUNDAY WIRE: ‚ÄòHail to the Deplo...\n",
       "22      Hillary Clinton Makes A Bipartisan Appeal on S...\n",
       "23      New Senate majority leader‚Äôs main goal for GOP...\n",
       "24      ‚ÄòInferno‚Äô and the Overpopulation Myth. Mises.o...\n",
       "25      Anti-Trump forces seek last-ditch delegate rev...\n",
       "26      Sanders Trounces Clinton in W. Va. -- But Will...\n",
       "27      Donald Trump Is Changing His Campaign Slogan t...\n",
       "28      Pure chaos: Donald Trump‚Äôs campaign management...\n",
       "29      Syrian War Report ‚Äì November 1, 2016: Syrian M...\n",
       "                              ...                        \n",
       "6305    Colin Kaepernick hosts ‚ÄòKnow Your Rights‚Äô camp...\n",
       "6306    Wikileaks Emails Disclose Aliens Linked to Vat...\n",
       "6307    US abstains from UN vote calling for end to Cu...\n",
       "6308    West Ham fans laud aerodynamic properties of n...\n",
       "6309    How the Obama White House runs foreign policy....\n",
       "6310    ISIS claims responsibility for Garland, Texas,...\n",
       "6311    The ‚Äúblame the left‚Äù crew: What the right‚Äôs ne...\n",
       "6312    ADHD NATION: How Big Pharma Created the ADHD E...\n",
       "6313    Donald Trump claims the election will be 'rigg...\n",
       "6314    REPORT: Dirty Reporter Blackmails Montel‚Ä¶ Help...\n",
       "6315    Police Arrest Suspect In Charleston Church Sho...\n",
       "6316    Donald Trump‚Äôs collapse was caused by one big ...\n",
       "6317    FINA suspends Russian swimmer for 8 years over...\n",
       "6318    BREAKING : Hillary Campaign Manager Deletes hi...\n",
       "6319    Why Ted Cruz Has the Most to Lose in New Hamps...\n",
       "6320    ‚ÄúNothing Good Can Come of This Election‚Äù‚Äìand T...\n",
       "6321    List of Republicans opposing Trump | OffGuardi...\n",
       "6322    Putin: Use of 'mythical' Russian military thre...\n",
       "6323    Bernie Sanders says private meeting with Pope ...\n",
       "6324    Alabama Lawmaker: Same-Sex Couples Don‚Äôt Deser...\n",
       "6325    Will the Media Reset After the Election or Are...\n",
       "6326    DOJ COMPLAINT: Comey Under Fire Over Partisan ...\n",
       "6327    GOP Senator David Perdue Jokes About Praying f...\n",
       "6328    Radio Derb Is On The Air‚ÄìLeonardo And Brazil‚Äôs...\n",
       "6329    Assange claims ‚Äòcrazed‚Äô Clinton campaign tried...\n",
       "6330    State Department says it can't find emails fro...\n",
       "6331    The ‚ÄòP‚Äô in PBS Should Stand for ‚ÄòPlutocratic‚Äô ...\n",
       "6332    Anti-Trump Protesters Are Tools of the Oligarc...\n",
       "6333    In Ethiopia, Obama seeks progress on peace, se...\n",
       "6334    Jeb Bush Is Suddenly Attacking Trump. Here's W...\n",
       "Name: title_text, Length: 6335, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_plus['title_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "45UDYZPXgn-9"
   },
   "source": [
    "### 2.3 Use regular expression to drop non-sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mcHHCDPR6b7b"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def cleanup(text):\n",
    "    if par_cased == 0: # transfer into lower text if par_cased is false\n",
    "        text = text.lower()\n",
    "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+','',text) # drop http[s]://*\n",
    "    text = re.sub(u\"\\\\{.*?}|\\\\[.*?]\",'',text) # drop [*]\n",
    "    text = re.sub(u\"\\(\\@.*?\\s\", '', text) # drop something like (@EP_President)\n",
    "    text = re.sub(u\"\\@.*?\\s\", '', text) # drop soething liek @EP_President\n",
    "    text = re.sub(u\"\\#.*?\\s\", '', text) # drop something like #EP_President (maybe hashtag)\n",
    "    text = re.sub(u\"\\¬© .*?\\s\", '', text) # drop something like ¬© EP_President\n",
    "    text = re.sub(r'pic.tw(?:[a-zA-Z]|[0-9]|[$-_@.&+#]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+','',text) # drop pic.twitter.com/*\n",
    "    text = re.sub(u\"\\*\\*\", '', text) # drop something like **Want FOX News First * in your inbox every day? Sign up here.**\n",
    "    text = re.sub(u\"ÔÇ∑|‚Ä¢|‚òÆÔ∏è|üíö|üåç|üòç|‚ô¶|‚ò¢\", '', text) # drop something like ÔÇ∑ and ‚Ä¢ etc\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HIGmUe8m14Dp"
   },
   "source": [
    "### 2.4 Use EDA method to augment the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "g-dwv1hn2G-z",
    "outputId": "d11ed894-5c46-4ddc-f08a-8e88bb13ee1d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.flow as nafc\n",
    "\n",
    "from nlpaug.util import Action\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LjGOgz4g19Fh"
   },
   "outputs": [],
   "source": [
    "if par_cased ==1:\n",
    "    aug = naf.Sequential([\n",
    "        naw.BertAug(action=\"substitute\", aug_p=0.8, aug_n=20,model_path='/home/notebooks/cased',tokenizer_path='bert-base-cased'),\n",
    "        #naw.BertAug(action=\"insert\", aug_p=0.1)\n",
    "    ])\n",
    "else:\n",
    "    aug = naf.Sequential([\n",
    "        naw.BertAug(action=\"substitute\", aug_p=0.8, aug_n=20,model_path='/home/notebooks/uncased',tokenizer_path='bert-base-uncased'),\n",
    "        #naw.BertAug(action=\"insert\", aug_p=0.1)\n",
    "    ])\n",
    "\n",
    "def aug_text(text):\n",
    "    text = aug.augment(text)\n",
    "    return(text)\n",
    "from nltk.tokenize import sent_tokenize\n",
    "def sentence_token_nltk(text):\n",
    "    sent_tokenize_list = sent_tokenize(text)\n",
    "    return sent_tokenize_list\n",
    "def eda_text(text):\n",
    "    if len(text) < 2:\n",
    "        return(text)\n",
    "    # split text into sentences\n",
    "    text = sentence_token_nltk(text)\n",
    "    if len(text) <= 1:\n",
    "        return(text)\n",
    "    if len(text) == 2:\n",
    "        for i in range(len(text)):\n",
    "            if i == 0:\n",
    "                tmp_text = text[i]\n",
    "            else:\n",
    "                tmp_text += text[i]\n",
    "        return(tmp_text)\n",
    "    # operate prior 3 sentences\n",
    "    for i in range(3):\n",
    "        if i == 0:\n",
    "            tmp_text = text[i]\n",
    "        else:\n",
    "            tmp_text += text[i]\n",
    "    zz = tokenizer.tokenize(tmp_text)\n",
    "    # operate proper sentences\n",
    "    if len(zz) <= 500:\n",
    "    #print(len(zz))\n",
    "        tmp_text = aug_text(tmp_text)\n",
    "    # conbine prior 3 sentences and rest sentences\n",
    "    for j in range(len(text)-3):\n",
    "        tmp_text += text[j+3]\n",
    "    return(tmp_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OoQnwTHv2S8z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "success\n",
      "7\n",
      "success\n",
      "13\n",
      "success\n",
      "19\n",
      "success\n",
      "25\n",
      "success\n",
      "31\n",
      "success\n",
      "37\n",
      "success\n",
      "43\n",
      "success\n",
      "49\n",
      "success\n",
      "55\n",
      "success\n",
      "61\n",
      "67\n",
      "success\n",
      "73\n",
      "success\n",
      "79\n",
      "success\n",
      "85\n",
      "success\n",
      "91\n",
      "success\n",
      "97\n",
      "success\n",
      "103\n",
      "success\n",
      "109\n",
      "success\n",
      "115\n",
      "success\n",
      "121\n",
      "success\n",
      "127\n",
      "success\n",
      "133\n",
      "success\n",
      "139\n",
      "success\n",
      "145\n",
      "success\n",
      "151\n",
      "success\n",
      "157\n",
      "163\n",
      "success\n",
      "169\n",
      "success\n",
      "175\n",
      "success\n",
      "181\n",
      "success\n",
      "187\n",
      "success\n",
      "193\n",
      "success\n",
      "199\n",
      "success\n",
      "205\n",
      "success\n",
      "211\n",
      "success\n",
      "217\n",
      "success\n",
      "223\n",
      "success\n",
      "229\n",
      "success\n",
      "235\n",
      "success\n",
      "241\n",
      "success\n",
      "247\n",
      "success\n",
      "253\n",
      "success\n",
      "259\n",
      "success\n",
      "265\n",
      "success\n",
      "271\n",
      "success\n",
      "277\n",
      "success\n",
      "283\n",
      "success\n",
      "289\n",
      "success\n",
      "295\n",
      "success\n",
      "301\n",
      "success\n",
      "307\n",
      "success\n",
      "313\n",
      "success\n",
      "319\n",
      "325\n",
      "success\n",
      "331\n",
      "success\n",
      "337\n",
      "success\n",
      "343\n",
      "success\n",
      "349\n",
      "success\n",
      "355\n",
      "success\n",
      "361\n",
      "success\n",
      "367\n",
      "success\n",
      "373\n",
      "success\n",
      "379\n",
      "success\n",
      "385\n",
      "success\n",
      "391\n",
      "success\n",
      "397\n",
      "success\n",
      "403\n",
      "success\n",
      "409\n",
      "success\n",
      "415\n",
      "success\n",
      "421\n",
      "success\n",
      "427\n",
      "success\n",
      "433\n",
      "success\n",
      "439\n",
      "success\n",
      "445\n",
      "success\n",
      "451\n",
      "success\n",
      "457\n",
      "success\n",
      "463\n",
      "success\n",
      "469\n",
      "success\n",
      "475\n",
      "success\n",
      "481\n",
      "487\n",
      "success\n",
      "493\n",
      "success\n",
      "499\n",
      "success\n",
      "505\n",
      "success\n",
      "511\n",
      "success\n",
      "517\n",
      "success\n",
      "523\n",
      "success\n",
      "529\n",
      "success\n",
      "535\n",
      "success\n",
      "541\n",
      "success\n",
      "547\n",
      "success\n",
      "553\n",
      "success\n",
      "559\n",
      "success\n",
      "565\n",
      "success\n",
      "571\n",
      "success\n",
      "577\n",
      "success\n",
      "583\n",
      "success\n",
      "589\n",
      "success\n",
      "595\n",
      "601\n",
      "success\n",
      "607\n",
      "success\n",
      "613\n",
      "success\n",
      "619\n",
      "success\n",
      "625\n",
      "success\n",
      "631\n",
      "success\n",
      "637\n",
      "success\n",
      "643\n",
      "success\n",
      "649\n",
      "success\n",
      "655\n",
      "661\n",
      "success\n",
      "667\n",
      "success\n",
      "673\n",
      "success\n",
      "679\n",
      "success\n",
      "685\n",
      "success\n",
      "691\n",
      "success\n",
      "697\n",
      "success\n",
      "703\n",
      "success\n",
      "709\n",
      "success\n",
      "715\n",
      "success\n",
      "721\n",
      "success\n",
      "727\n",
      "success\n",
      "733\n",
      "success\n",
      "739\n",
      "success\n",
      "745\n",
      "success\n",
      "751\n",
      "success\n",
      "757\n",
      "success\n",
      "763\n",
      "success\n",
      "769\n",
      "success\n",
      "775\n",
      "success\n",
      "781\n",
      "success\n",
      "787\n",
      "success\n",
      "793\n",
      "success\n",
      "799\n",
      "success\n",
      "805\n",
      "811\n",
      "success\n",
      "817\n",
      "success\n",
      "823\n",
      "success\n",
      "829\n",
      "success\n",
      "835\n",
      "success\n",
      "841\n",
      "success\n",
      "847\n",
      "success\n",
      "853\n",
      "success\n",
      "859\n",
      "success\n",
      "865\n",
      "success\n",
      "871\n",
      "success\n",
      "877\n",
      "success\n",
      "883\n",
      "success\n",
      "889\n",
      "success\n",
      "895\n",
      "success\n",
      "901\n",
      "success\n",
      "907\n",
      "success\n",
      "913\n",
      "success\n",
      "919\n",
      "925\n",
      "success\n",
      "931\n",
      "success\n",
      "937\n",
      "success\n",
      "943\n",
      "success\n",
      "949\n",
      "success\n",
      "955\n",
      "success\n",
      "961\n",
      "success\n",
      "967\n",
      "success\n",
      "973\n",
      "success\n",
      "979\n",
      "success\n",
      "985\n",
      "success\n",
      "991\n",
      "success\n",
      "997\n",
      "success\n",
      "1003\n",
      "success\n",
      "1009\n",
      "success\n",
      "1015\n",
      "success\n",
      "1021\n",
      "success\n",
      "1027\n",
      "success\n",
      "1033\n",
      "success\n",
      "1039\n",
      "success\n",
      "1045\n",
      "success\n",
      "1051\n",
      "success\n",
      "1057\n",
      "success\n",
      "1063\n",
      "success\n",
      "1069\n",
      "success\n",
      "1075\n",
      "success\n",
      "1081\n",
      "success\n",
      "1087\n",
      "success\n",
      "1093\n",
      "success\n",
      "1099\n",
      "success\n",
      "1105\n",
      "success\n",
      "1111\n",
      "success\n",
      "1117\n",
      "success\n",
      "1123\n",
      "success\n",
      "1129\n",
      "success\n",
      "1135\n",
      "success\n",
      "1141\n",
      "success\n",
      "1147\n",
      "success\n",
      "1153\n",
      "success\n",
      "1159\n",
      "success\n",
      "1165\n",
      "success\n",
      "1171\n",
      "success\n",
      "1177\n",
      "success\n",
      "1183\n",
      "success\n",
      "1189\n",
      "success\n",
      "1195\n",
      "success\n",
      "1201\n",
      "success\n",
      "1207\n",
      "success\n",
      "1213\n",
      "success\n",
      "1219\n",
      "success\n",
      "1225\n",
      "success\n",
      "1231\n",
      "success\n",
      "1237\n",
      "success\n",
      "1243\n",
      "success\n",
      "1249\n",
      "success\n",
      "1255\n",
      "success\n",
      "1261\n",
      "success\n",
      "1267\n",
      "success\n",
      "1273\n",
      "success\n",
      "1279\n",
      "success\n",
      "1285\n",
      "success\n",
      "1291\n",
      "success\n",
      "1297\n",
      "success\n",
      "1303\n",
      "success\n",
      "1309\n",
      "success\n",
      "1315\n",
      "success\n",
      "1321\n",
      "success\n",
      "1327\n",
      "success\n",
      "1333\n",
      "success\n",
      "1339\n",
      "success\n",
      "1345\n",
      "success\n",
      "1351\n",
      "success\n",
      "1357\n",
      "success\n",
      "1363\n",
      "success\n",
      "1369\n",
      "success\n",
      "1375\n",
      "success\n",
      "1381\n",
      "success\n",
      "1387\n",
      "success\n",
      "1393\n",
      "success\n",
      "1399\n",
      "success\n",
      "1405\n",
      "success\n",
      "1411\n",
      "success\n",
      "1417\n",
      "success\n",
      "1423\n",
      "success\n",
      "1429\n",
      "success\n",
      "1435\n",
      "success\n",
      "1441\n",
      "success\n",
      "1447\n",
      "success\n",
      "1453\n",
      "success\n",
      "1459\n",
      "success\n",
      "1465\n",
      "success\n",
      "1471\n",
      "success\n",
      "1477\n",
      "success\n",
      "1483\n",
      "success\n",
      "1489\n",
      "success\n",
      "1495\n",
      "success\n",
      "1501\n",
      "success\n",
      "1507\n",
      "success\n",
      "1513\n",
      "success\n",
      "1519\n",
      "success\n",
      "1525\n",
      "success\n",
      "1531\n",
      "success\n",
      "1537\n",
      "success\n",
      "1543\n",
      "success\n",
      "1549\n",
      "success\n",
      "1555\n",
      "success\n",
      "1561\n",
      "success\n",
      "1567\n",
      "success\n",
      "1573\n",
      "success\n",
      "1579\n",
      "success\n",
      "1585\n",
      "1591\n",
      "success\n",
      "1597\n",
      "1603\n",
      "success\n",
      "1609\n",
      "success\n",
      "1615\n",
      "success\n",
      "1621\n",
      "success\n",
      "1627\n",
      "success\n",
      "1633\n",
      "success\n",
      "1639\n",
      "success\n",
      "1645\n",
      "success\n",
      "1651\n",
      "success\n",
      "1657\n",
      "success\n",
      "1663\n",
      "success\n",
      "1669\n",
      "success\n",
      "1675\n",
      "success\n",
      "1681\n",
      "success\n",
      "1687\n",
      "success\n",
      "1693\n",
      "success\n",
      "1699\n",
      "success\n",
      "1705\n",
      "success\n",
      "1711\n",
      "success\n",
      "1717\n",
      "success\n",
      "1723\n",
      "success\n",
      "1729\n",
      "success\n",
      "1735\n",
      "success\n",
      "1741\n",
      "success\n",
      "1747\n",
      "1753\n",
      "success\n",
      "1759\n",
      "success\n",
      "1765\n",
      "success\n",
      "1771\n",
      "success\n",
      "1777\n",
      "success\n",
      "1783\n",
      "success\n",
      "1789\n",
      "success\n",
      "1795\n",
      "success\n",
      "1801\n",
      "success\n",
      "1807\n",
      "success\n",
      "1813\n",
      "success\n",
      "1819\n",
      "success\n",
      "1825\n",
      "success\n",
      "1831\n",
      "success\n",
      "1837\n",
      "success\n",
      "1843\n",
      "success\n",
      "1849\n",
      "success\n",
      "1855\n",
      "success\n",
      "1861\n",
      "success\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-a803923d9682>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m6\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m           \u001b[0mdat_plus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meda_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat_plus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m           \u001b[0mdat_plus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat_plus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-63-f334a016f73b>\u001b[0m in \u001b[0;36meda_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m#print(len(zz))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mtmp_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maug_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0;31m# conbine prior 3 sentences and rest sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-63-f334a016f73b>\u001b[0m in \u001b[0;36maug_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      4\u001b[0m ])\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maug_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nlpaug/flow/sequential.py\u001b[0m in \u001b[0;36maugment\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0maugmented_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0maug\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                 \u001b[0maugmented_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maugmented_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maugmented_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nlpaug/base_augmenter.py\u001b[0m in \u001b[0;36maugment\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mAction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSUBSTITUTE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubstitute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mAction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSWAP\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nlpaug/augmenter/word/bert.py\u001b[0m in \u001b[0;36msubstitute\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maug_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maug_idxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0moriginal_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maug_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mcandidate_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maug_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0msubstitute_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nlpaug/model/lang_models/bert.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input_tokens, target_word, top_n)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# Predict target word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegments_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mtop_score_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, masked_lm_labels)\u001b[0m\n\u001b[1;32m    860\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked_lm_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m         sequence_output, _ = self.bert(input_ids, token_type_ids, attention_mask,\n\u001b[0;32m--> 862\u001b[0;31m                                        output_all_encoded_layers=False)\n\u001b[0m\u001b[1;32m    863\u001b[0m         \u001b[0mprediction_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m    731\u001b[0m         encoded_layers = self.encoder(embedding_output,\n\u001b[1;32m    732\u001b[0m                                       \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m                                       output_all_encoded_layers=output_all_encoded_layers)\n\u001b[0m\u001b[1;32m    734\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoded_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0mall_encoder_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_module\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moutput_all_encoded_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0mall_encoder_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask)\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if par_eda == 1: # use eda to operate sentences when par_eda is true\n",
    "  for i in range(len(dat_plus['title_text'])):\n",
    "      if i%6 == 1:       \n",
    "          print(i)\n",
    "          dat_plus['title_text'][i] = copy.deepcopy(eda_text(dat_plus['title_text'][i]))\n",
    "          dat_plus['title_text'][i] = \"\".join(dat_plus['title_text'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LVlYr2tBeviS"
   },
   "source": [
    "## 3. Google Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hJfGe_Xgl-ej"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "#F.softmax(logits,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dUHs73jbnXgs"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "if par_cleanup == 1:\n",
    "    X = dat_plus['title_text'].apply(cleanup)\n",
    "else:\n",
    "    X = dat_plus['title_text']\n",
    "y = dat_plus['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V0cLEcbluu5v"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.values.tolist()\n",
    "X_test = X_test.values.tolist()\n",
    "\n",
    "y_train = pd.get_dummies(y_train).values.tolist() # convert to one-hot encoding\n",
    "y_test = pd.get_dummies(y_test).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OQHWRmRbu032"
   },
   "outputs": [],
   "source": [
    "max_seq_length = 256\n",
    "class text_dataset(Dataset):\n",
    "    def __init__(self,x_y_list, transform=None):\n",
    "        \n",
    "        self.x_y_list = x_y_list\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        \n",
    "        tokenized_title_text = tokenizer.tokenize(self.x_y_list[0][index])\n",
    "        \n",
    "        if len(tokenized_title_text) > max_seq_length:\n",
    "            tokenized_title_text = tokenized_title_text[:max_seq_length]\n",
    "            \n",
    "        ids_title_text  = tokenizer.convert_tokens_to_ids(tokenized_title_text) #tokens->input_ids\n",
    "\n",
    "        padding = [0] * (max_seq_length - len(ids_title_text))\n",
    "        \n",
    "        ids_title_text += padding # use padding to make the same ids\n",
    "        \n",
    "        assert len(ids_title_text) == max_seq_length\n",
    "        \n",
    "        #print(ids_title_text)\n",
    "        ids_title_text = torch.tensor(ids_title_text)\n",
    "        \n",
    "        label = self.x_y_list[1][index] # color        \n",
    "        list_of_labels = [torch.from_numpy(np.array(label))]\n",
    "        \n",
    "        \n",
    "        return ids_title_text, list_of_labels[0]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x_y_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hi3JVNQ9lrZs"
   },
   "source": [
    "### 3.1 Create data dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ld2UJCTyu9YD"
   },
   "outputs": [],
   "source": [
    "batch_size = 16 # divide into 16 batches\n",
    "\n",
    "train_lists = [X_train, y_train]\n",
    "test_lists = [X_test, y_test]\n",
    "\n",
    "training_dataset = text_dataset(x_y_list = train_lists )\n",
    "\n",
    "test_dataset = text_dataset(x_y_list = test_lists )\n",
    "\n",
    "dataloaders_dict = {'train': torch.utils.data.DataLoader(training_dataset, batch_size=batch_size, shuffle=True, num_workers=0),\n",
    "                   'val':torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "                  }                \n",
    "dataset_sizes = {'train':len(train_lists[0]),\n",
    "                'val':len(test_lists[0])}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0--pWHgflxXm"
   },
   "source": [
    "### 3.2 Define the train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oHewydswvAi2"
   },
   "outputs": [],
   "source": [
    " def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    print('starting')\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 100\n",
    "    best_f1 = 0.978\n",
    "    best_acc_test = 0.96\n",
    "    best_acc_train = 0.96\n",
    "    best_auc = 0.96\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            \n",
    "            label_corrects = 0\n",
    "            TP = 0\n",
    "            TN = 0\n",
    "            FN = 0\n",
    "            FP = 0\n",
    "            total_scores = []\n",
    "            total_tar = []\n",
    "            # Iterate over data.\n",
    "            for inputs, label in dataloaders_dict[phase]:\n",
    "                #inputs = inputs\n",
    "                #print(len(inputs),type(inputs),inputs)\n",
    "                #inputs = torch.from_numpy(np.array(inputs)).to(device) \n",
    "                inputs = inputs.to(device) \n",
    "                label = label.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    #print(inputs)\n",
    "                    outputs = model(inputs)\n",
    "\n",
    "                    outputs = F.softmax(outputs,dim=1)\n",
    "                    \n",
    "                    loss = criterion(outputs, torch.max(label.float(), 1)[1])\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        \n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                label_corrects += torch.sum(torch.max(outputs, 1)[1] == torch.max(label, 1)[1]) #ËøîÂõûÊØè‰∏ÄË°å‰∏≠ÊúÄÂ§ßÂÄºÁöÑÈÇ£‰∏™ÂÖÉÁ¥†Ôºå‰∏îËøîÂõûÂÖ∂Á¥¢ÂºïÔºàËøîÂõûÊúÄÂ§ßÂÖÉÁ¥†Âú®Ëøô‰∏ÄË°åÁöÑÂàóÁ¥¢ÂºïÔºâ\n",
    "                pred_choice = torch.max(outputs, 1)[1]\n",
    "                target = torch.max(label, 1)[1]\n",
    "                scores = pred_choice.cpu().tolist()\n",
    "                tar = target.cpu().tolist()\n",
    "                total_scores = total_scores + scores\n",
    "                total_tar = total_tar + tar\n",
    "\n",
    "                tmp_tp = 0\n",
    "                tmp_tn = 0\n",
    "                tmp_fn = 0\n",
    "                tmp_fp = 0\n",
    "                if pred_choice.numel()!= target.numel():\n",
    "                    print(\"error\")\n",
    "                for i in range(pred_choice.numel()):\n",
    "                    if pred_choice[i] == 1 and target[i] == 1 :\n",
    "                        tmp_tp = tmp_tp + 1\n",
    "                    elif pred_choice[i] == 0 and target[i] == 0 :\n",
    "                        tmp_tn = tmp_tn + 1\n",
    "                    elif pred_choice[i] == 0 and target[i] == 1 :\n",
    "                        tmp_fn = tmp_fn + 1\n",
    "                    elif pred_choice[i] == 1 and target[i] == 0 :\n",
    "                        tmp_fp = tmp_fp + 1\n",
    "                # TP    both predict and label are 1\n",
    "                TP += tmp_tp\n",
    "                # TN    both predict and label are 0\n",
    "                TN += tmp_tn\n",
    "                # FN    predict 0 label 1\n",
    "                FN += tmp_fn\n",
    "                # FP    predict 1 label 0\n",
    "                FP += tmp_fp\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            p = TP / (TP + FP)\n",
    "            r = TP / (TP + FN)\n",
    "            F1 = 2 * r * p / (r + p)\n",
    "            acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "            ### draw ROC curce\n",
    "            tpr = TP/(TP+FN)\n",
    "            fpr = FP/(FP+TN)\n",
    "            tnr = TN/(FP+TN)\n",
    "\n",
    "            total_scores = np.array(total_scores)\n",
    "            total_tar = np.array(total_tar)\n",
    "            fpr, tpr, thresholds = roc_curve(total_tar, total_scores)\n",
    "            roc_auc = auc(fpr, tpr) \n",
    "            plt.title('ROC')\n",
    "            if roc_auc > best_auc:\n",
    "                best_auc = roc_auc\n",
    "            if epoch < num_epochs -1:\n",
    "                plt.plot(fpr, tpr,'b',label='AUC = %0.4f'% roc_auc)\n",
    "            if epoch == num_epochs -1:\n",
    "                plt.plot(fpr, tpr, color='darkorange', label='MAX AUC = %0.4f'% best_auc) \n",
    "            plt.legend(loc='lower right')\n",
    "            plt.plot([0,1],[0,1],'r--')\n",
    "            plt.ylabel('TPR')\n",
    "            plt.xlabel('FPR')\n",
    "            plt.show()\n",
    "\n",
    "            #print('{} p: {:.4f} '.format(phase,p ))\n",
    "            #print('{} r: {:.4f} '.format(phase,r ))\n",
    "            print('{} F1: {:.4f} '.format(phase,F1 ))\n",
    "            print('{} accuracy: {:.4f} '.format(phase,acc ))\n",
    "\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                print('saving with loss of {}'.format(epoch_loss),\n",
    "                      'improved over previous {}'.format(best_loss))\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                #torch.save(model.state_dict(), '/content/drive/My Drive/Colab Notebooks/bert_model_test_loss.pth')\n",
    "            if F1 > best_f1:\n",
    "                best_f1 = F1\n",
    "            if phase == 'val' and acc > best_acc_test:\n",
    "                best_acc_test = acc\n",
    "            if phase == 'train' and acc > best_acc_train:\n",
    "                best_acc_train = acc\n",
    "                #best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                #torch.save(model.state_dict(), '/content/drive/My Drive/Colab Notebooks/bert_model_test_f1.pth')\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print(\"Parament setting: \")\n",
    "    print(\"cased: \",par_cased)\n",
    "    print(\"cleanup: \",par_cleanup)\n",
    "    print(\"eda: \",par_eda)\n",
    "    print('Best train Acc: {:4f}'.format(float(best_acc_train)))\n",
    "    print('Best test Acc: {:4f}'.format(float(best_acc_test)))\n",
    "    print('Best f1 score: {:4f}'.format(float(best_f1)))\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v_VbFXgInDdK"
   },
   "source": [
    "## 4. Final Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JBuf0RudnH_q"
   },
   "source": [
    "### 4.1 Model details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4gz9E3N4K-Fv"
   },
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xZ_fh5u9vD9P"
   },
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "\n",
    "#model.freeze_bert_encoder()\n",
    "#model.classifier.weight.requires_grad = True\n",
    "#    def freeze_bert_encoder(self):\n",
    "#        for param in self.bert.parameters():\n",
    "#            param.requires_grad = False\n",
    "#    \n",
    "#    def unfreeze_bert_encoder(self):\n",
    "#        for param in self.bert.parameters():\n",
    "#            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yyqaPeDMvG02"
   },
   "outputs": [],
   "source": [
    "lrlast = .001\n",
    "lrmain = .00001\n",
    "optim1 = optim.Adam(\n",
    "    [\n",
    "        {\"params\":model.bert.parameters(),\"lr\": lrmain},\n",
    "        {\"params\":model.classifier.parameters(), \"lr\": lrlast},\n",
    "       \n",
    "   ])\n",
    "\n",
    "#optim1 = optim.Adam(model.parameters(), lr=0.001)#,momentum=.9)\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim1\n",
    "criterion = nn.CrossEntropyLoss() # loss function\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LNTRoNa1nOiy"
   },
   "source": [
    "### 4.2 F1 and other para details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yMzajPCgwqiy"
   },
   "outputs": [],
   "source": [
    "model_ft1 = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=10)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Bert_v3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
